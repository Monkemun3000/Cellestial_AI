{
  "title": "Spatial and temporal characteristics of vestibular convergence",
  "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3166430/",
  "pmc_id": "3166430",
  "content": "Spatial and temporal characteristics of vestibular convergence Contact information for corresponding author: Dr. J. David Dickman, Department of Anatomy & Neurobiology, Box 8108, 660 S. Euclid, Washington University School of Medicine, St. Louis, MO 63110, Tel: 314-747-7221, Fax: 314-747-7206,ddickman@wustl.edu In all species studied, afferents from semicircular canals and otolith organs converge on central neurons in the brainstem. However, the spatial and temporal relationships between converging inputs and how these contribute to vestibular behaviors is not well understood. In the current study, we used discrete rotational and translational motion stimuli to characterize canal- and otolith-driven response components of convergent non-eye movement (NEM) neurons in the vestibular nuclear complex of alert pigeons. When compared to afferent responses, convergent canal signals had similar gain and phase ranges but exhibited greater spatial variability in their axes of preferred rotation. Convergent otolith signals also had similar mean gain and phase values to the afferent population but were spatially well-matched with the corresponding canal signals, cell-by-cell. However, neither response component alone nor a simple linear combination of these components was sufficient to predict actual net responses during combined canal-otolith stimulation. We discuss these findings in the context of previous studies of pigeon vestibular behaviors, and we compare our findings to similar studies in other species. The vestibular system consists of biological sensors that detect head movements in space. The semicircular canals and otolith organs detect angular and linear head accelerations, respectively. In the brainstem, canal and otolith afferents terminate on neurons in the vestibular nuclear complex (VNC). Neuroanatomical studies in many species have shown overlap between canal and otolith afferent projection regions in the brainstem (Carleton and Carpenter 1984;Dickman and Fang 1996;Kevetter and Perachio 1986;Kuruvilla et al. 1985;Newlands and Perachio 2003;Schwarz and Schwarz 1986). Direct convergence of canal and otolith afferents onto single VNC neurons has also been demonstrated using electrical nerve stimulation (Uchino et al. 2000;Zakir et al. 2000). Further, electrophysiological recordings from VNC neurons using discrete rotational and translational stimuli have characterized the dynamic properties and tuning characteristics of both convergent and non-convergent cells (Dickman and Angelaki 2002;Kasper, Schor and Wilson 1988;Tomlinson, McConville and Na 1996;Yakushin, Raphan and Cohen 2006). In the current study, we used simple motion stimuli to characterize canal-otolith convergence onto single NEM neurons in the VNC. Earth-vertical axis (EVA) rotations were used to characterize neural responses to canal inputs in the absence of dynamic otolith stimulation. Linear translations were used to characterize responses to otolith inputs in the absence of dynamic canal stimulation. Earth-horizontal axis (EHA) rotations dynamically stimulate the canals and otolith organs, since these rotations reorient the head relative to gravity and change the net linear acceleration sensed by the otolith organs. Thus, EHA rotations were used to characterize responses to combined canal and otolith stimulation, to provide a foundation for our understanding of how these signals are neurally integrated. Twelve adult pigeons (Columba livia, 400–700g, Double T Farm, Glenwood IA) were used in accordance with the guidelines set forth by the National Institutes of Health Guide for the Care and Use of Animals in Research, as well as those approved by the Institutional Animal Studies Committee. The animals were housed and cared for in the Laboratory Animal Facilities under veterinary supervision. The protocol and analyses were adapted from a previous study in primates (Dickman and Angelaki 2002). General anesthesia was achieved using isofluorane gas (3–5% in O2) via endotracheal intubation. Heart rate was monitored, and core temperature (40°C) was maintained with a heating pad. Each bird was surgically implanted with a delrin head stud and a recording electrode guide platform. An incision was made along the skull midline, and the underlying periosteum was removed from the bone. The head was positioned stereotaxically with the beak angled approximately 12° downward, such that upright orientation of the head stud and recording platform corresponded on average to alignment of the horizontal canals with an earth-horizontal plane (Dickman 1996). The head stud (5x5x10mm) was attached to the skull with titanium self-tapping screws and secured with dental acrylic. In addition, a circular delrin recording platform (15mm diameter, 5mm depth) was attached to the skull posterior to the head stud. The platform was pre-drilled with a staggered array of holes (0.8mm apart) that extended from the midline to the area overlying the vestibular nerves (bilaterally). After surgery, butorphanol (10mg/kg) was administered for post-operative pain, and the head wound margin was kept clean with betadine washes and antibiotic ointment. Following a 5–7 day recovery period, five pigeons underwent an additional surgery to implant a scleral search coil in one eye to monitor eye movements. The coil was constructed of three turns of multi-stranded wire (Teflon-coated, 41-gauge stainless steel, A-M Systems) and coated in a thin layer of Araldite epoxy (Huntsman). Under surgical anesthesia (as described above), a circumferential incision was made in the conjuctiva to allow visualization of the sclera. In pigeons, the sclera is calcified near the cornea, so the coil was attached to the posterior margin of the scleral globe with 8-0 prolene sutures. Coil wire leads were threaded through the bone of the posterior orbit and underneath the skin to exit near the head stud. The conjuctiva was approximated over the coil and closed with 8-0 vicryl sutures. Lead wires were soldered to a nanoconnector (Omnetics) and secured next to the head stud with dental acrylic. After surgery, butorphanol (10mg/kg) was administered for post-operative pain, and ophthalmic antibiotic ointment (bacytracin/neomycin) was applied to the operated eye. Pigeons were allowed to fully recover (7–10 days) before being used in experiments. For each experiment, the pigeon was placed in a padded body holder, and the head stud was fixed in an upright position to the body holder. The holder was then secured to a servo-controlled rotator/sled system (Neurokinetics) driven by a PC and programmable interface (CED Model 1401plus, Cambridge Electronic Design). Stimulus control and data acquisition were performed using custom scripts written for the interface environment (Spike2, Cambridge Electronic Design). All stimuli were delivered along axes that passed through the center of the pigeon’s head (i.e. intersection of nasooccipital and interaural axes), and all experiments were performed in total darkness with the pigeon head-fixed. Stimulus delivery was monitored using a rate sensor and 3-axis linear accelerometer mounted near the animal’s head, the outputs of which were low-pass filtered (200Hz, 6-pole Bessel), digitized, and stored for off-line analyses. A three-field AC magnetic coil system (CNC Engineering) mounted to the motion system was used to monitor eye movements. The coil system provided a 5-in homogeneous magnetic field cube centered about the pigeon’s head. Eye coil signals were also low-pass filtered (200Hz, 6-pole Bessel), digitized, and stored. However, the eye movement signals were primarily used online to categorize cells as eye movement sensitive (EM) or non-eye movement sensitive (NEM) neurons. Extracellular recordings from single neurons in the vestibular nuclei were obtained using epoxy-coated tungsten microelectrodes (FHC, 10–15MΩ). The electrode was inserted into a 26-gauge stainless steel guide tube, advanced through one of the pre-drilled guide holes in the recording platform, then manipulated in depth with a remote control hydraulic microdrive (FHC). Neural activity was amplified, filtered (300Hz-10kHz), and passed through a dual time-amplitude window discriminator (BAK Instruments). Single-unit spikes triggered acceptance pulses that were stored as events for off-line analyses. The stereotaxic coordinates of the vestibular nuclei have been mapped in pigeons (Dickman and Fang 1996), and we used these coordinates to guide our recording site locations. Reconstruction of electrode tracks indicated that most neurons were recorded from the superior (SVN) or lateral (LVN) vestibular nuclei. During each electrode penetration, we searched for spontaneously active neurons that were sensitive to 0.5Hz sinusoidal rotations and linear translations along any of the three cardinal head axes. We also monitored spontaneous activity in the absence of motion, to determine if each cell was responsive to extra-vestibular cues such as eye movements. For the subset of pigeons implanted with a scleral search coil, voltages corresponding to eye movements were monitored and compared to neural firing in real time. For pigeons without a search coil, large eye movements (gaze shifts) were directly observed by the experimenter in the light. If a neuron’s firing rate correlated with eye movements (i.e. modulation with changes in eye position, burst and/or pause in firing during saccades), that neuron was classified as eye movement-sensitive (EM) and excluded from the current study. Some neurons exhibited firing rate modulations in the absence of motion that were not clearly correlated with eye movements, possibly due to proprioceptive, somatosensory, or motor efferent input. In practice, only those motion-sensitive neurons that did not significantly modulate their firing rates in the absence of motion were classified as non-eye movement (NEM) neurons and studied further. Responses of a single representative convergent neuron to dynamic motion stimulation of semicircular canals only (A: Earth-vertical axis rotation, EVAR), otolith organs only (B: Linear translation), and both canals and otolith organs simultaneously (C: Earth-horizontal axis rotation, EHAR). Single-unit action potentials are plotted as instantaneous firing rates (IFR). Stimulus feedback for each motion trial is also shown (angular velocity, °/s; linear acceleration, g). Axis orientations are expressed relative to the head cardinal axes, using the right-hand rule. All data analyses were performed off-line using custom scripts in Matlab (Mathworks). For each motion trial, a neuron’s stored spike times (events) were converted to instantaneous firing rates (IFR), computed as the inverse of the interspike intervals and assigned to the end of each interval. Steady-state stimulus feedback and IFR data were fit with sinusoidal functions at the fundamental stimulus frequency using nonlinear least-squares minimization (Levenberg-Marquardt). The relationship between motion stimulus and neural response was evaluated by comparing the parameters of their sinusoidal fits. Neural sensitivity (also referred to as gain) served as a comparison of the amplitude of the neural response (DC-to-peak) to the amplitude of the stimulus. Neural phase indicated the temporal relationship between the peak of the neural response and the peak of the stimulus, expressed as a phase angle (°) within a single representative sinusoidal cycle. For example, if the stimulus frequency was 0.5Hz and the peak of the neural response preceded the peak of the stimulus by 0.5s, the phase of the neural response relative to the stimulus would be computed as +90° (since 0.5s corresponds to one-fourth of a full cycle). For translational stimuli, neural sensitivity was expressed as the amplitude of IFR modulation divided by the amplitude of linear acceleration modulation (spk/s per g), and neural response phase was computed as the phase angle difference (°) between peak IFR and peak head-horizontal linear acceleration. For rotational stimuli, sensitivity was expressed as the amplitude of IFR modulation divided by the amplitude of angular velocity modulation (spk/s per °/s), and phase was computed as the phase angle difference (°) between peak IFR and peak angular velocity. Based on their sensitivity to rotation and translation, neurons were classified according to their likely vestibular afferent inputs (Angelaki, Bush and Perachio 1993;Dickman and Angelaki 2002;Estes, Blanks and Markham 1975). EVA rotation dynamically stimulates the semicircular canals but not the otolith organs, so neurons that responded to at least one axis of EVA rotation were considered to receive either direct or indirect input from semicircular canal afferents. Similarly, since linear translation dynamically stimulates the otolith organs but not the canals, neurons that responded to at least one axis of linear translation were considered to receive direct or indirect otolith afferent inputs. After examining the distribution of gain values across neurons, we selected a value of 0.1 spk/s per °/s during EVA rotation or 10 spk/s per g during linear translation (for at least one axis of stimulation) as the minimum gain of a neuron identified as receiving canal or otolith input, respectively. Neurons with gains exceeding the criterion value for both EVA rotation and linear translation were classified as canal-otolith convergent neurons, and only these neurons were considered further. This method may have excluded some neurons that in fact received convergent inputs but with lower sensitivities. For each convergent neuron, we characterized the nature of its canal and otolith inputs by fitting cosine tuning functions to the responses recorded during EVA rotation and linear translation, respectively. Then, we used these tuning functions to determine the orientation of the earth-horizontal axis (EHA) rotation that would evoke maximum modulation of each input (canal- and otolith-related) and the corresponding amplitude and timing of that modulation relative to the EHA rotation stimulus. Finally, for a subset of neurons, we characterized the actual net response to EHA rotation and compared its tuning parameters to those predicted by a simple linear summation of the canal and otolith inputs. For any cosine tuning function, there will be two possible orientations of the maximum sensitivity vector, oriented 180° apart in space with equal gains but opposite phase values. For each cell, we have reported data for the maximum sensitivity vectors corresponding to phase values within the range +90°, unless otherwise noted. Though neurons were recorded bilaterally, maximum sensitivity vector orientations and phase values were reported as though all neurons were recorded from the left hemisphere. For example, a neuron with a maximum sensitivity EVA rotation vector oriented upward preferred ipsilateral (leftward) rotation, according to the right hand rule. A three-dimensional cosine tuning function was fit to the sensitivity and phase values obtained from each neuron’s responses during EVA rotations (0.5Hz, 20o/s), yielding a maximum sensitivity vector for the semicircular canal (CANAL) inputs with direction αCANAL, sensitivity SCANAL, and phase θCANAL(Dickman 1996;Dickman and Angelaki 2002). A two-dimensional cosine tuning function was fit to the sensitivity and phase values obtained from each neuron’s responses during earth-horizontal translations (0.5Hz, 0.2g), yielding a maximum sensitivity vector for otolith organ (OTO) inputs with direction αOTO, sensitivity SOTO, and phase θOTO. A two-dimensional spatiotemporal convergence (STC) tuning function was also fit to the translation response data (Angelaki, Bush and Perachio 1993;Angelaki and Dickman 2000;Bush, Perachio and Angelaki 1993;Dickman and Angelaki 2002) and compared to the cosine tuning function for goodness-of-fit, using the variance accounted for: VAF = 1 − (sum square error of the fit/sum square difference of the data from its mean) (Dickman and Angelaki 2002). For each neuron, we used the translation tuning function with the best fit (i.e. highest VAF) for further analyses. However, since the simple cosine function provided a good description of tuning for most neurons tested, we did not consider STC response behavior further in the current study. EHA rotation – otolith stimulation To facilitate an understanding of the analyses used to predict and characterize responses to EHA rotation, we present here a description of the canal and otolith organ components of EHA rotational stimulation experienced by the animal. When the head was positioned upright, the head-vertical axis was considered to be parallel to earth-vertical, and the otolith organs responded to a static linear acceleration due to gravity, represented as a 1g vector directed upward along the head-vertical axis. (Note: This vector is oriented upward because the otolith organs – like all linear accelerometers – signal the vector deviation from freefall, not the vector of force due to gravity.) During sinusoidal EHA rotation, the orientation of the linear acceleration vector swings in the head within the plane of rotation. One can decompose the vector orientation into a head-vertical modulation component and a head-horizontal component, both of which vary as a function of the head’s angular displacement (i.e. orientation relative to gravity). The head-horizontal component of linear acceleration modulates at the same frequency as rotation, with peak amplitude equal to one minus the sine of the peak displacement angle. The head-vertical component of net linear acceleration modulates at the 2ndharmonic of the rotation frequency, with an amplitude equal to one minus the cosine of the peak displacement angle. For example, consider the case of 0.5Hz EHA rotation about the pitch axis with peak velocity of 20°/s. The peak head tilt is ~6.4° ( = peak velocity/2*pi*frequency), and the head rotates between +6.4° (nose-down) and −6.4° (nose-up). The head-horizontal (fore-aft/nasooccipital) linear acceleration modulates around 0g with modulation amplitude of sin(6.4 °); thus, it modulates from −0.1g (nose-down) and +0.1g (nose-up). The head-vertical (up-down/dorsoventral) linear acceleration modulates around +1g with modulation amplitude of cos(6.4°). However, this modulation in head-vertical acceleration modulates at the 2ndharmonic of the rotation frequency, equal to +0.99g at both nose-down and nose-up positions. Note that the modulation in head-vertical linear acceleration (0.01g) is an order of magnitude smaller than the modulation in head-horizontal linear acceleration (0.1g). EHA rotation – predicted canal and otolith inputs The relationship between predicted canal- and otolith-driven contributions to EHA rotation responses was assessed cell-by-cell, by fitting linear regressions relatingcanalvectootovec,canalStootoS, andcanalphasetootophase, using a procedure modified for use with two dependent variables. This procedure minimizes perpendicular errors between actual data points and the estimated linear regression through them, and the corresponding 95% confidence intervals (obtained by bootstrapping) may be asymmetrical. The significance of the regression was assessed by calculating R and p values (alpha = 0.05). If the linear regression provided a significant fit to the data and if the range defined by the confidence intervals on the slope included a value of one, we concluded that the regression slope was not significantly different from unity, indicating a cell-by-cell match between canal and otolith inputs for a given response parameter. If the linear regression did not provide a significant fit to the data, we concluded that canal and otolith input values were not linearly related, and the regression was not plotted in the corresponding figure. EHA rotation – actual vs. predicted net responses For the subset of neurons with sufficient data, actual responses to EHA rotation were compared to responses predicted by a linear combination of canal and otolith response components. Actual EHA rotation maximum sensitivity vectors (αEHAR), sensitivity (SEHAR), and phase (θEHAR) values were obtained by fitting a two-dimensional cosine tuning function to the available EHA rotation data. We selected the axis of EHA rotation that yielded the highest predicted sensitivity value and defined the corresponding axis orientation. sensitivity, and phase as the predicted αEHAR, SEHAR, and θEHAR, respectively. To calculate the predicted αEHAR, SEHAR, and θEHARvalues, we performed a linear summation (in the complex plane) of the canal and otolith responses to each axis of EHA rotation (sampled every 1°), based on the EVA rotation and linear translation tuning functions, respectively. To assess the relationship between actual and predicted values, we fit a linear regression for two dependent variables (as described above) to the data for αEHAR, SEHAR, and θEHAR. If the linear regression provided a significant fit to the data and if the range defined by the confidence intervals on the slope included a value of one, we concluded that the regression slope was not significantly different from unity, indicating that the linear summation model provided a good estimate of the actual response to EHA rotation. If the linear regression did not provide a significant fit to the data, we concluded that there was not a significant linear relationship between actual and predicted values, and the regression was not plotted in the corresponding figure. Canal-only responses: earth-vertical axis rotations Responses of convergent neurons (n=37) to earth-vertical axis (EVA) rotation (0.5Hz, 20°/s). A: Axes of maximum sensitivity (αCANAL) are plotted as unit vectors in three-dimensional head space. Mean maximum sensitivity vectors for pigeon horizontal (red), anterior (blue), and posterior (green) canal afferents are also shown (thick lines;Dickman 1996). B: Maximum sensitivity (SCANAL) and phase (θCANAL) values are expressed relative to angular velocity, with the population mean indicated by the open circle. Mean sensitivity and phase values (open triangles) are also shown for pigeon horizontal (red), anterior (blue), and posterior (green) canal afferents (Dickman 1996). Boxes indicate afferent means ± standard deviation. Otolith-only responses: linear translations Responses of convergent neurons (n=43) to earth-horizontal linear translation (0.5Hz, 0.2g). A: Axes of maximum sensitivity (αOTO) are plotted as unit vectors in two-dimensional head space. B: Maximum sensitivity (SOTO) and phase (θOTO) values are expressed relative to linear acceleration, with the population mean indicated by the open circle. The mean pigeon otolith afferent sensitivity and phase is indicated by the open triangle, and the box indicates the corresponding standard deviation (Si, Angelaki and Dickman 1997). Relationship between canal and otolith inputs Predicted responses of canal and otolith inputs to convergent neurons (n=25) during earth-horizontal axis (EHA) rotation (0.5Hz, 20°/s). Significant linear regressions (solid) are plotted through the available data, and the unity slope line (dotted) is plotted for comparison. A: Axes of maximum sensitivity for canal (canalvec) and otolith (otovec) inputs to each neuron, expressed as polar angle orientations relative to the positive x-axis. Regression slope = 1.2 (95% CI = [0.9, 1.4], R = 0.92, p < 0.001. Unity slope line +30° (shaded) is plotted for comparison. B: Response sensitivity values of canal (canalS) and otolith (otoS) inputs to each neuron, expressed relative to angular velocity. Open symbols indicate those neurons with very low (<0.1) predicted canal sensitivity to EHA rotation. C: Response phases of canal (canalphase) and otolith (otophase) inputs to each neuron, expressed relative to angular velocity. Combined canal and otolith stimulation: responses to EHA rotation Actual responses to earth-horizontal axis (EHA) rotation (0.5Hz, 20°/s) were compared to predicted responses based on a linear summation of canal- and otolith-related responses. Significant linear regressions (solid) are plotted through the available data, and the unity slope line (dotted) ± 0.1 or 30° (shaded) is plotted for comparison. A: Axes of maximum sensitivity to EHA rotation (αEHAR), expressed as polar angle orientations relative to the positive x-axis. Regression slope = 0.99 (95% CI = [0.7, 1.4], R = 0.90, p < 0.001. B: Response sensitivity (SEHAR) values for EHA rotation around the maximum sensitivity axis, expressed relative to angular velocity. Regression slope = 0.7 (95% CI = [0.1, 2.1]), R = 0.6, p = 0.06 (outlier plotted with an open symbol). C: Response phase (θMAX) values for EHA rotation around the maximum sensitivity axis, expressed relative to angular velocity (outlier plotted with an open symbol). Convergent canal- and otolith-related responses are spatially aligned Convergent VNC neurons showed a stronger preference for linear translation within canal planes than did the otolith afferents, which loosely tend to prefer interaural translation (Si, Angelaki and Dickman 1997). There was also a paucity of convergent VNC cells with maximum sensitivity vectors near the nasooccipital axis, similar to central convergent neuron populations recorded in rats (Angelaki, Bush and Perachio 1993) and monkeys (Dickman and Angelaki 2002;Zhou et al. 2006). Further, VNC convergent neurons exhibited a striking spatial alignment between canal- and otolith-driven responses, consistent with maximal activation of both canal and otolith inputs during EHA rotation around the same axis. Similar spatial alignment has been observed in rats (Angelaki, Bush and Perachio 1993) and cats (Perlmutter et al. 1999), while the majority of convergent neurons in monkeys did not exhibit this spatial input alignment (Dickman and Angelaki 2002). What is the functional significance of the spatial alignment of convergent inputs in NEM neurons in the vestibular brainstem? For pigeons and other lateral-eyed animals, both canal and otolith stimulation contribute to compensatory eye and head responses that stabilize gaze during rotation relative to gravity (i.e. EHA rotation; pigeon:Dickman and Angelaki 1999;Dickman, Beyer and Hess 2000;McArthur and Dickman 2008; mouse:Harrod and Baker 2003; rat:Brettler et al. 2000; rabbit:Barmack 1981). Specifically in pigeons, we have demonstrated that a dynamic net head-horizontal linear acceleration signal improves the phase of both eye and head responses to EHA tilt (McArthur and Dickman 2008). Indeed, the canal- and otolith-driven components of these responses are spatially aligned with one another when examined separately (Dickman and Angelaki 1999;McArthur and Dickman 2008). Thus, the fact that otolith inputs were spatially aligned with canal inputs for central neurons supports the idea that the functional role of otolith signals in pigeons is to cooperate with primarily canal-driven reflexes, rather than generating other, primarily otolith-driven reflexes with different spatial demands (e.g. translational VOR in primates). Sensitivity and phase for convergent canal- and otolith-related inputs are mismatched Convergent inputs do not sum linearly during EHA rotation EHA rotation dynamically modulates both canal and otolith inputs to convergent neurons. How do neurons integrate these two types of inputs when both are dynamically stimulated? One possibility was that convergent neurons simply computed a linear sum of canal and otolith inputs during EHA rotation. In a previous study (McArthur and Dickman 2008), we demonstrated that linear summation of canal- and otolith-driven response components provided a good characterization of compensatory eye (VOR) but not head (VCR) response gain and phase during EHA rotation. In the current study, linear summation failed to provide a good fit to the available gain and phase data for convergent neurons, consistent with nonlinear integration of canal and otolith inputs. Spatiotemporal matching: different species, different stages? What kind of nonlinear processing might be carried out by convergent VNC neurons, and what purpose might this serve for the animal? We can only speculate regarding this issue, as there was insufficient data in the current study to rigorously fit alternative models of canal-otolith integration. However, others have provided insight from studies in non-human primates, where canal and otolith signals are combined to construct central representations of the animal’s movements in space. Canal afferents alone cannot reference the animal’s rotations to a space-fixed reference frame, since the semicircular canals are fixed in the head. Otolith afferents alone cannot disambiguate gravitational and translational linear accelerations, as the otolith organs detect net gravito-inertial linear acceleration. Populations of central neurons can perform these computations via nonlinear integration of canal and otolith afferent signals, whereby rotational signals are decomposed into EHA and EVA components and linear acceleration signals are decomposed into gravitational and translational components (Angelaki et al., 2004; Yakusheva et al., 2010). Modeling studies, grounded in behavioral and electrophysiological data, suggest that these computations require intermediate populations of convergent neurons, whose canal and otolith inputs are spatiotemporally matched (Green and Angelaki, 2004;2007). This matching need not occur at the level of an individual neuron, however, as long as the distributions of spatial preference, sensitivity, and phase match on average (Green and Angelaki, 2004;2007). Further, each type of matching need not occur at the same level, i.e. the same anatomical location in the brain. In primates, distinct populations of neurons in the brainstem, cerebellar cortex, and deep cerebellar nuclei exhibit different degrees of input matching and nonlinear processing. Convergent neurons in the primate VNC not only exhibit a wide distribution of gain and phase values, but also lack the degree of input spatial matching that we saw in the pigeon (Dickman and Angelaki 2002). While there was a trend across the primate population for convergent canal and otolith inputs to prefer the same axis of EHA rotation, this was not generally observed for individual cells. In the cerebellar cortex, however, convergent canal- and otolith-driven inputs were tightly matched for both sensitivity and phase (Angelaki et al. 2010). We characterize brainstem neurons receiving convergent canal and otolith input. Convergent inputs were spatially aligned when co-stimulated during tilt. Convergent inputs were temporally out of phase during tilt co-stimulation. Net responses to tilt were not predicted by a linear combination of convergent inputs. Publisher's Disclaimer:This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final citable form. Please note that during the production process errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.",
  "content_length": 31403,
  "scraped_date": "2025-10-04 11:55:19"
}